import discord
import os
from discord.ext import commands
from discord import app_commands
from collections import defaultdict
from datetime import datetime, timedelta

# Import de la biblioth√®que officielle Hugging Face
from huggingface_hub import AsyncInferenceClient
from huggingface_hub.utils import HfHubHTTPError
import asyncio


class AIchat(commands.Cog):
    def __init__(self, bot: commands.Bot):
        self.bot = bot

    # --- Commandes Slash ---
    @app_commands.command(name="ask", description="Pose une question √† l'IA (Llama 3)")
    @app_commands.describe(question="La question que tu veux poser")
    async def ask(self, interaction: discord.Interaction, question: str):
        """Commande principale pour interroger l'IA"""

        # V√©rification du rate limit
        is_allowed, wait_time = check_rate_limit(interaction.user.id)
        if not is_allowed:
            await interaction.response.send_message(
                f"‚è≥ Vous avez atteint la limite de requ√™tes. "
                f"Veuillez patienter {wait_time} secondes.",
                ephemeral=True,
            )
            return

        # Validation de la question
        if len(question) > 500:
            await interaction.response.send_message(
                "‚ùå Votre question est trop longue (maximum 500 caract√®res).",
                ephemeral=True,
            )
            return

        # D√©f√©rer la r√©ponse imm√©diatement
        try:
            await interaction.response.defer()
        except discord.errors.NotFound:
            print("‚ö†Ô∏è L'interaction a expir√© avant que le bot ne puisse r√©pondre.")
            return

        # Construire l'historique de conversation
        history = get_conversation_history(interaction.user.id)

        # Message syst√®me (toujours en premier)
        messages = [
            {
                "role": "system",
                "content": (
                    "Tu incarnes Paul-Louis Courier, un √©rudit et "
                    "√©crivain fran√ßais. "
                    "Tes r√©ponses sont claires, concises, pr√©cises et "
                    "r√©dig√©es dans un fran√ßais "
                    "soutenu mais accessible. Tu es professionnel, "
                    "courtois et vas droit au but. "
                    "Tu peux faire r√©f√©rence aux messages pr√©c√©dents "
                    "de la conversation."
                ),
            }
        ]

        # Ajouter l'historique (si existant)
        messages.extend(history)

        # Ajouter la nouvelle question
        messages.append({"role": "user", "content": question})

        try:
            separator = "=" * 50
            print(f"\n{separator}")
            print("üì® Nouvelle requ√™te /ask")
            print(f"üë§ Utilisateur : {interaction.user.name} (ID: {interaction.user.id})")
            print(f"‚ùì Question : {question}")
            print(f"üí¨ Historique : {len(history)} messages")
            print(f"{separator}\n")

            # Appel √† l'API Hugging Face
            response = await asyncio.wait_for(
                hf_client.chat_completion(
                    model=MODEL_ID,
                    messages=messages,
                    max_tokens=600,  # Augment√© pour r√©ponses
                    temperature=0.7,
                    stream=False,
                ),
                timeout=30.0,  # Timeout de 30 secondes
            )

            # Extraction de la r√©ponse
            reponse_ia = response.choices[0].message.content.strip()

            # Ajouter √† l'historique
            add_to_conversation(interaction.user.id, "user", question)
            add_to_conversation(interaction.user.id, "assistant", reponse_ia)

            # Pr√©parer le message
            embed = discord.Embed(
                title="üí¨ R√©ponse de Paul-Louis Courier", color=discord.Color.green()
            )
            embed.add_field(name="üìù Votre question", value=question, inline=False)

            # Tronquer si n√©cessaire
            reponse_finale = truncate_response(reponse_ia)
            embed.add_field(name="‚úçÔ∏è R√©ponse", value=reponse_finale, inline=False)

            # Ajouter un footer avec info de conversation
            history_len = len(get_conversation_history(interaction.user.id))
            embed.set_footer(
                text=(
                    f"üíæ Conversation : {history_len // 2} √©changes | "
                    "Utilisez /clear pour r√©initialiser"
                )
            )

            await interaction.followup.send(embed=embed)

            print(f"‚úÖ R√©ponse envoy√©e avec succ√®s √† {interaction.user.name}")

        except asyncio.TimeoutError:
            print("‚è±Ô∏è Timeout : L'API a mis trop de temps √† r√©pondre")
            await interaction.followup.send(
                "‚è±Ô∏è L'API a mis trop de temps √† r√©pondre. Veuillez r√©essayer.",
                ephemeral=True,
            )

        except HfHubHTTPError as e:
            print(f"‚ùå Erreur HTTP de l'API Hugging Face : {e}")
            await interaction.followup.send(
                "‚ö†Ô∏è Une erreur est survenue avec l'API de "
                "Hugging Face.\n"
                f"```{e.server_message}```",
                ephemeral=True,
            )

        except Exception as e:
            print(f"‚ùå Erreur inattendue : {type(e).__name__}: {e}")
            await interaction.followup.send(
                "‚ùå Une erreur inattendue est survenue. "
                "Consultez la console pour plus de d√©tails.",
                ephemeral=True,
            )

    @app_commands.command(
        name="clear", description="Efface l'historique de ta conversation avec l'IA"
    )
    async def clear(self, interaction: discord.Interaction):
        """R√©initialise l'historique de conversation de l'utilisateur"""
        clear_conversation(interaction.user.id)

        embed = discord.Embed(
            title="üóëÔ∏è Conversation r√©initialis√©e",
            description=("Votre historique de conversation a √©t√© effac√© avec succ√®s !"),
            color=discord.Color.orange(),
        )
        await interaction.response.send_message(embed=embed, ephemeral=True)
        print(f"üóëÔ∏è Conversation effac√©e pour {interaction.user.name}")


DISCORD_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
HF_TOKEN = os.getenv("HF_TOKEN")

# Mod√®le utilis√©
MODEL_ID = "meta-llama/Meta-Llama-3-8B-Instruct"

# Configuration du rate limiting (5 requ√™tes par minute par utilisateur)
RATE_LIMIT_REQUESTS = 5
RATE_LIMIT_WINDOW = 60

# Client IA initialis√© une seule fois
hf_client = AsyncInferenceClient(token=HF_TOKEN)

# Syst√®me de rate limiting simple
user_requests = defaultdict(list)

# Stockage des conversations (limit√© dans le temps)
conversations = {}
CONVERSATION_TIMEOUT = 600  # 10 minutes

# --- 3. Fonctions Utilitaires ---


def check_rate_limit(user_id: int) -> tuple[bool, int]:
    """
    V√©rifie si l'utilisateur a d√©pass√© la limite de requ√™tes.
    Retourne (est_autoris√©, temps_restant_en_secondes)
    """
    now = datetime.now()
    cutoff = now - timedelta(seconds=RATE_LIMIT_WINDOW)

    # Nettoyer les anciennes requ√™tes
    user_requests[user_id] = [
        req_time for req_time in user_requests[user_id] if req_time > cutoff
    ]

    if len(user_requests[user_id]) >= RATE_LIMIT_REQUESTS:
        oldest_request = user_requests[user_id][0]
        window_delta = timedelta(seconds=RATE_LIMIT_WINDOW)
        wait_time = int((oldest_request + window_delta - now).total_seconds())
        return False, wait_time

    user_requests[user_id].append(now)
    return True, 0


def get_conversation_history(user_id: int) -> list:
    """R√©cup√®re l'historique de conversation d'un utilisateur"""
    if user_id not in conversations:
        conversations[user_id] = {"messages": [], "last_activity": datetime.now()}

    # V√©rifier si la conversation n'a pas expir√©
    timeout_delta = timedelta(seconds=CONVERSATION_TIMEOUT)
    time_elapsed = datetime.now() - conversations[user_id]["last_activity"]
    if time_elapsed > timeout_delta:
        conversations[user_id]["messages"] = []

    conversations[user_id]["last_activity"] = datetime.now()
    return conversations[user_id]["messages"]


def add_to_conversation(user_id: int, role: str, content: str):
    """Ajoute un message √† l'historique de conversation"""
    history = get_conversation_history(user_id)
    history.append({"role": role, "content": content})

    # Limiter √† 10 derniers √©changes (20 messages)
    if len(history) > 20:
        # Garde le premier message syst√®me et les 19 derniers
        conversations[user_id]["messages"] = history[-19:]


def clear_conversation(user_id: int):
    """Efface l'historique de conversation d'un utilisateur"""
    if user_id in conversations:
        conversations[user_id]["messages"] = []


def truncate_response(reponse: str, max_length: int = 1900) -> str:
    """Tronque une r√©ponse √† la derni√®re phrase compl√®te"""
    if len(reponse) <= max_length:
        return reponse

    # Couper √† la derni√®re phrase compl√®te
    truncated = reponse[:max_length]
    last_period = max(truncated.rfind("."), truncated.rfind("!"), truncated.rfind("?"))

    if last_period > max_length * 0.7:
        suffix = "\n\n*[R√©ponse tronqu√©e]*"
        return truncated[: last_period + 1] + suffix

    return truncated + "...\n\n*[R√©ponse tronqu√©e]*"


async def setup(bot):
    await bot.add_cog(AIchat(bot))
